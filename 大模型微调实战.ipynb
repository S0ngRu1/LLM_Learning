{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f18007-ef8c-4ac8-a6fc-8e3467fb2807",
   "metadata": {},
   "source": [
    "# å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4094739-1d8c-4281-ad18-f45f0eb172dd",
   "metadata": {},
   "source": [
    "## å®‰è£…éœ€è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20a2a49-ec57-43ab-a254-aae6b94ef525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T01:12:04.850675Z",
     "iopub.status.busy": "2025-08-15T01:12:04.850304Z",
     "iopub.status.idle": "2025-08-15T01:12:10.251936Z",
     "shell.execute_reply": "2025-08-15T01:12:10.251208Z",
     "shell.execute_reply.started": "2025-08-15T01:12:04.850655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting swanlab\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/92/5c/aee5fdcaa1b6de64f1f505d66e07d748cfd995948f9bda1edf506d50bf5e/swanlab-0.6.8-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.0/290.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.35.49 in /usr/local/lib/python3.11/site-packages (from swanlab) (1.39.3)\n",
      "Requirement already satisfied: botocore in /usr/local/lib/python3.11/site-packages (from swanlab) (1.39.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from swanlab) (8.1.8)\n",
      "Requirement already satisfied: platformdirs>=4.2.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (7.0.0)\n",
      "Requirement already satisfied: pydantic>=2.9.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (2.11.7)\n",
      "Collecting pyecharts>=2.0.0 (from swanlab)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ae/18/383622b338e4f6948ba1b75a8155d748ce097ead08a4163ca763f0ad510e/pyecharts-2.0.8-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pynvml in /usr/local/lib/python3.11/site-packages (from swanlab) (12.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from swanlab) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (13.9.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from swanlab) (65.5.1)\n",
      "Collecting swankit==0.2.4 (from swanlab)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4a/c7/7cc8d6bc562ce96d751a7655421eae09ba795cd557ed4791d63a72bd8f9a/swankit-0.2.4-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.17.0 in /usr/local/lib/python3.11/site-packages (from swanlab) (1.17.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/site-packages (from boto3>=1.35.49->swanlab) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/site-packages (from boto3>=1.35.49->swanlab) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/site-packages (from botocore->swanlab) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.9.0->swanlab) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.9.0->swanlab) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.9.0->swanlab) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.9.0->swanlab) (0.4.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from pyecharts>=2.0.0->swanlab) (3.1.6)\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/site-packages (from pyecharts>=2.0.0->swanlab) (3.16.0)\n",
      "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/site-packages (from pyecharts>=2.0.0->swanlab) (3.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.28.0->swanlab) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.28.0->swanlab) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.28.0->swanlab) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich<14.0.0,>=13.6.0->swanlab) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich<14.0.0,>=13.6.0->swanlab) (2.19.1)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/site-packages (from pynvml->swanlab) (12.575.51)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->swanlab) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->swanlab) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->pyecharts>=2.0.0->swanlab) (3.0.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/site-packages (from prettytable->pyecharts>=2.0.0->swanlab) (0.2.13)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: swankit, pyecharts, swanlab\n",
      "Successfully installed pyecharts-2.0.8 swankit-0.2.4 swanlab-0.6.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install swanlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520915f-02da-4809-9e19-f3d8bb8aa725",
   "metadata": {},
   "source": [
    "## æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7a3241-06d1-4af5-ba25-a51293d682ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:23:47.566963Z",
     "iopub.status.busy": "2025-08-14T07:23:47.566634Z",
     "iopub.status.idle": "2025-08-14T07:24:09.266959Z",
     "shell.execute_reply": "2025-08-14T07:24:09.266465Z",
     "shell.execute_reply.started": "2025-08-14T07:23:47.566942Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is loading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading [README.md]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.33k/1.33k [00:00<00:00, 8.97MB/s]\n",
      "2025-08-14 15:23:57,375 - modelscope - INFO - storing https://www.modelscope.cn/api/v1/datasets/krisfu/delicate_medical_r1_data/repo?Source=SDK&Revision=master&FilePath=README.md&View=False in cache at /mnt/workspace/.cache/modelscope/hub/datasets/06b8db8bcdfac6b78df6a26d6969f81867cc1311bc9ce4384b5fb1cffc9504c9\n",
      "2025-08-14 15:23:57,391 - modelscope - INFO - creating metadata file for /mnt/workspace/.cache/modelscope/hub/datasets/06b8db8bcdfac6b78df6a26d6969f81867cc1311bc9ce4384b5fb1cffc9504c9\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.20M/9.20M [00:00<00:00, 10.9MB/s]\n",
      "2025-08-14 15:24:07,917 - modelscope - INFO - storing https://www.modelscope.cn/api/v1/datasets/krisfu/delicate_medical_r1_data/repo?Source=SDK&Revision=master&FilePath=r1_data_example.jsonl in cache at /mnt/workspace/.cache/modelscope/hub/datasets/downloads/01b7be597488efa04be3c3838a6cb36d08f9b1e99874a112d52790dd4050ad78\n",
      "2025-08-14 15:24:07,932 - modelscope - INFO - creating metadata file for /mnt/workspace/.cache/modelscope/hub/datasets/downloads/01b7be597488efa04be3c3838a6cb36d08f9b1e99874a112d52790dd4050ad78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868d8b99e3714f33889a4cdc8b834f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been split successfully.\n",
      "Train Set Sizeï¼š2166\n",
      "Val Set Sizeï¼š241\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "print(f\"The dataset is loading.\")\n",
    "ds = MsDataset.load('krisfu/delicate_medical_r1_data', subset_name='default', split='train')\n",
    "data_list = list(ds)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "split_idx = int(len(data_list) * 0.9)\n",
    "\n",
    "train_data = data_list[:split_idx]\n",
    "val_data = data_list[split_idx:]\n",
    "\n",
    "with open('train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in train_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('val.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in val_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "print(f\"The dataset has been split successfully.\")\n",
    "print(f\"Train Set Sizeï¼š{len(train_data)}\")\n",
    "print(f\"Val Set Sizeï¼š{len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e741c9-60c2-4163-b30c-2cf33aa8b884",
   "metadata": {},
   "source": [
    "## æŸ¥çœ‹æ•°æ®æ ·æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a0f684-5a3d-46de-85e8-9bcd2d7a23f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:26:31.939914Z",
     "iopub.status.busy": "2025-08-14T07:26:31.939486Z",
     "iopub.status.idle": "2025-08-14T07:26:31.990495Z",
     "shell.execute_reply": "2025-08-14T07:26:31.990085Z",
     "shell.execute_reply.started": "2025-08-14T07:26:31.939894Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'è¯´æ˜æµ‹å®šç›é…¸ç”²æ°§æ˜æ³¨å°„æ¶²å«é‡çš„å…·ä½“æ­¥éª¤ã€‚',\n",
       " 'question': 'åŒ»ç”Ÿï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹å¦‚ä½•æµ‹å®šç›é…¸ç”²æ°§æ˜æ³¨å°„æ¶²çš„å«é‡ï¼Œå…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ',\n",
       " 'think': 'å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯å¦‚ä½•æµ‹å®šç›é…¸ç”²æ°§æ˜æ³¨å°„æ¶²çš„å«é‡ï¼Œå…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦å›å¿†ä¸€ä¸‹ç›¸å…³çš„åˆ†ææ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯è¯å…¸ä¸­å¸¸ç”¨çš„æ–¹æ³•ã€‚ç›é…¸ç”²æ°§æ˜å±äºè¯ç‰©åˆ†æä¸­çš„å¸¸è§æˆåˆ†ï¼Œé€šå¸¸å¯èƒ½ç”¨ç´«å¤–åˆ†å…‰å…‰åº¦æ³•æˆ–è€…HPLCä¹‹ç±»çš„ã€‚\\n\\né¦–å…ˆï¼Œç”¨æˆ·æåˆ°çš„æ˜¯ç´«å¤–-å¯è§åˆ†å…‰å…‰åº¦æ³•ï¼Œè¿™åº”è¯¥æ˜¯æ¯”è¾ƒç›´æ¥çš„æ–¹æ³•ã€‚é‚£æ­¥éª¤çš„è¯ï¼Œé¦–å…ˆåº”è¯¥è€ƒè™‘æ ·å“çš„åˆ¶å¤‡ã€‚å› ä¸ºæ³¨å°„æ¶²æµ“åº¦å¯èƒ½è¾ƒé«˜ï¼Œéœ€è¦ç¨€é‡Šåˆ°åˆé€‚çš„æµ“åº¦èŒƒå›´ï¼Œä½¿å¾—å¸å…‰åº¦åœ¨ä»ªå™¨çš„çº¿æ€§èŒƒå›´å†…ã€‚æ¯”å¦‚ï¼Œå…ˆå–ä¸€å®šé‡çš„æ³¨å°„æ¶²ï¼Œç„¶åç¨€é‡Šåˆ°æŸä¸ªä½“ç§¯ï¼Œæ¯”å¦‚250æ¯«å‡çš„é‡ç“¶ï¼Œè¿™æ ·å¯èƒ½æ˜¯ä¸€ä¸ªæ­¥éª¤ã€‚\\n\\næ¥ä¸‹æ¥ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¨€é‡Šï¼Œå› ä¸ºç¬¬ä¸€æ¬¡ç¨€é‡Šåçš„æº¶æ¶²å¯èƒ½å¸å…‰åº¦è¿˜æ˜¯å¤ªé«˜æˆ–è€…å¤ªä½ã€‚æ¯”å¦‚ï¼Œä»ç¬¬ä¸€æ¬¡ç¨€é‡Šåçš„æº¶æ¶²ä¸­å†å–ä¸€éƒ¨åˆ†ï¼Œæ¯”å¦‚10æ¯«å‡ï¼Œæ”¾åˆ°å¦ä¸€ä¸ªé‡ç“¶ï¼Œæ¯”å¦‚100æ¯«å‡ï¼Œå†æ¬¡ç¨€é‡Šã€‚è¿™æ ·ä¸¤æ¬¡ç¨€é‡Šå¯ä»¥å¾—åˆ°åˆé€‚çš„æµ“åº¦ã€‚\\n\\nç„¶åï¼Œæµ‹å®šå¸å…‰åº¦çš„æ—¶å€™ï¼Œæ³¢é•¿çš„é€‰æ‹©å¾ˆé‡è¦ã€‚ç›é…¸ç”²æ°§æ˜çš„æœ€å¤§å¸æ”¶æ³¢é•¿åº”è¯¥æŸ¥æ–‡çŒ®æˆ–è€…è¯å…¸ï¼Œæ¯”å¦‚é—®é¢˜ä¸­çš„ç­”æ¡ˆæåˆ°çš„æ˜¯290çº³ç±³ï¼Œè¿™å¯èƒ½æ¥è‡ªè¯å…¸çš„è§„å®šã€‚éœ€è¦ç¡®è®¤è¿™ä¸ªæ³¢é•¿æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠå¸æ”¶ç³»æ•°æ˜¯å¦å‡†ç¡®ã€‚æ¯”å¦‚ï¼Œå¸æ”¶ç³»æ•°137æ˜¯å¦å¯¹åº”C1H1NO3Â·HClçš„è®¡ç®—ï¼Œå¯èƒ½éœ€è¦æ ¹æ®åˆ†å­é‡å’Œæµ“åº¦æ¥è®¡ç®—ï¼Œä½†ç”¨æˆ·å¯èƒ½ä¸éœ€è¦è¯¦ç»†è®¡ç®—ï¼Œåªéœ€è¦æ­¥éª¤ã€‚\\n\\nå¦å¤–ï¼Œæ­¥éª¤ä¸­çš„ç²¾å¯†é‡å–éœ€è¦æ³¨æ„ï¼Œæ¯”å¦‚ä½¿ç”¨ç§»æ¶²ç®¡æˆ–è€…è‡ªåŠ¨è¿›æ ·å™¨ï¼Œç¡®ä¿é‡å–çš„å‡†ç¡®æ€§ã€‚æ‘‡åŒ€ä¹Ÿæ˜¯å…³é”®æ­¥éª¤ï¼Œç¡®ä¿æº¶æ¶²å‡åŒ€ï¼Œé¿å…å±€éƒ¨æµ“åº¦ä¸å‡å¯¼è‡´è¯¯å·®ã€‚\\n\\nå¯èƒ½è¿˜éœ€è¦è€ƒè™‘ç©ºç™½å¯¹ç…§ï¼Œæ¯”å¦‚ç”¨æ°´ä»£æ›¿æ ·å“ï¼Œè¿›è¡ŒåŒæ ·çš„æ“ä½œï¼Œä»¥æ‰£é™¤èƒŒæ™¯å¸å…‰åº¦ã€‚ä¸è¿‡ç­”æ¡ˆä¸­æ²¡æœ‰æåˆ°ï¼Œå¯èƒ½åœ¨æ ‡å‡†æ–¹æ³•ä¸­å·²ç»åŒ…å«ï¼Œæˆ–è€…æ­¥éª¤ç®€åŒ–äº†ã€‚ä½†ä½œä¸ºè¯¦ç»†æ­¥éª¤ï¼Œå¯èƒ½éœ€è¦è¡¥å……è¿™ä¸€ç‚¹ã€‚\\n\\næœ€åï¼Œè®¡ç®—å«é‡çš„æ—¶å€™ï¼Œæ ¹æ®å¸æ”¶ç³»æ•°å’Œå¸å…‰åº¦ï¼Œåº”ç”¨æœ—ä¼¯-æ¯”å°”å®šå¾‹ï¼ŒA=Îµclï¼Œå…¶ä¸­Îµæ˜¯æ‘©å°”å¸å…‰ç³»æ•°ï¼Œä½†è¿™é‡Œå¯èƒ½ç”¨çš„æ˜¯ç™¾åˆ†å¸æ”¶ç³»æ•°ï¼ˆ1% 1cmï¼‰ï¼Œæ‰€ä»¥éœ€è¦ç¡®è®¤å•ä½æ˜¯å¦æ­£ç¡®ã€‚ä¾‹å¦‚ï¼Œå¸æ”¶ç³»æ•°137å¯èƒ½æ˜¯æŒ‡åœ¨1%æµ“åº¦ï¼ˆ1g/100mlï¼‰ä¸‹ï¼Œ1cmå…‰ç¨‹çš„å¸å…‰åº¦ï¼Œè¿™æ ·è®¡ç®—æ—¶éœ€è¦å°†æµ“åº¦è½¬æ¢ä¸ºç›¸åº”çš„å•ä½ã€‚\\n\\nå¯èƒ½ç”¨æˆ·æ˜¯åŒ»ç”Ÿæˆ–è€…è¯å‰‚å¸ˆï¼Œéœ€è¦å‡†ç¡®çš„æ­¥éª¤æ¥æ‰§è¡Œæˆ–ç†è§£æ£€æµ‹æµç¨‹ï¼Œæ‰€ä»¥æ­¥éª¤è¦æ¸…æ™°ï¼Œç¬¦åˆè¯å…¸æ ‡å‡†ã€‚éœ€è¦ç¡®ä¿æ­¥éª¤ä¸­çš„æ¯ä¸ªæ“ä½œéƒ½æœ‰ä¾æ®ï¼Œæ¯”å¦‚é‡å–çš„ä½“ç§¯ã€ç¨€é‡Šå€æ•°ã€æ³¢é•¿é€‰æ‹©ç­‰ï¼Œéƒ½ç¬¦åˆè¯å…¸æ¨èçš„æ–¹æ³•ï¼Œè¿™æ ·ç»“æœæ‰å¯é ã€‚\\n\\næ€»ç»“ä¸‹æ¥ï¼Œæ­¥éª¤åº”è¯¥æ˜¯ï¼šå–æ ·ã€ä¸¤æ¬¡ç¨€é‡Šã€æµ‹å®šå¸å…‰åº¦ã€è®¡ç®—å«é‡ã€‚åŒæ—¶è¦å¼ºè°ƒæ–¹æ³•çš„å‡†ç¡®æ€§å’Œè¯å…¸æ¨èï¼Œè®©ç”¨æˆ·çŸ¥é“è¿™æ˜¯æ ‡å‡†æ–¹æ³•ï¼Œå¯ä¿¡åº¦é«˜ã€‚\\n',\n",
       " 'answer': 'æ‚¨å¥½ï¼Œæµ‹å®šç›é…¸ç”²æ°§æ˜æ³¨å°„æ¶²çš„å«é‡é€šå¸¸é‡‡ç”¨ç´«å¤–-å¯è§åˆ†å…‰å…‰åº¦æ³•ã€‚é¦–å…ˆï¼Œéœ€è¦ç²¾å¯†é‡å–é€‚é‡çš„æ³¨å°„æ¶²ï¼ˆå¤§çº¦ç›¸å½“äº100æ¯«å…‹ç›é…¸ç”²æ°§æ˜ï¼‰ï¼Œå°†å…¶ç½®äº250æ¯«å‡çš„é‡ç“¶ä¸­ï¼Œå¹¶ç”¨æ°´ç¨€é‡Šè‡³åˆ»åº¦çº¿ï¼Œå……åˆ†æ‘‡åŒ€ã€‚ç„¶åï¼Œä»è¿™ä¸ªæº¶æ¶²ä¸­ç²¾å¯†é‡å–10æ¯«å‡ï¼Œæ”¾å…¥100æ¯«å‡çš„é‡ç“¶ä¸­ï¼Œå†æ¬¡ç”¨æ°´ç¨€é‡Šè‡³åˆ»åº¦çº¿ï¼Œæ‘‡åŒ€ã€‚æœ€åï¼Œä½¿ç”¨ç´«å¤–-å¯è§åˆ†å…‰å…‰åº¦è®¡ï¼Œåœ¨290çº³ç±³çš„æ³¢é•¿å¤„æµ‹å®šå¸å…‰åº¦ï¼Œæ ¹æ®C1H1NO3Â·HClçš„å¸æ”¶ç³»æ•°137æ¥è®¡ç®—ç›é…¸ç”²æ°§æ˜çš„å«é‡ã€‚è¿™ç§æ–¹æ³•å‡†ç¡®å¯é ï¼Œæ˜¯è¯å…¸æ¨èçš„æµ‹å®šæ–¹æ³•ã€‚',\n",
       " 'metrics': {'quality_f1': 1.0}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('train.jsonl') as f:\n",
    "  content = f.readlines()\n",
    "\n",
    "datas = []\n",
    "for data in content:\n",
    "  datas.append(json.loads(data))\n",
    "\n",
    "datas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035ce38-2eba-405a-88fc-aabd9d734791",
   "metadata": {},
   "source": [
    "## åŠ è½½æ¨¡å‹æƒé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18128b59-20af-4b99-878e-09db33aa0934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:27:00.650734Z",
     "iopub.status.busy": "2025-08-14T07:27:00.650436Z",
     "iopub.status.idle": "2025-08-14T07:28:21.503508Z",
     "shell.execute_reply": "2025-08-14T07:28:21.503052Z",
     "shell.execute_reply.started": "2025-08-14T07:27:00.650715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 15:27:03.855289: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 15:27:04.129664: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-14 15:27:05.324863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: ./Qwen/Qwen3-1.7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 15:27:07,980 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-08-14 15:27:08,158 - modelscope - INFO - Got 12 files, start to download ...\n",
      "Processing 12 items:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1b9684463b457284ac6df5101157a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf1d50b1fd04e22850b585229cf0bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00002-of-00002.safetensors]:   0%|          | 0.00/594M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9d0b902afd4c61beed2111524e0137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors.index.json]:   0%|          | 0.00/25.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e6e8e9650d4a06818bb708d2535665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00001-of-00002.safetensors]:   0%|          | 0.00/3.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c476dc01e6ea4d0595d9777825764f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d565e67407e44b695bb80917db05baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6ff6293de242a3935b9d25bcaf4440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [merges.txt]:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a42ed28aab405caba9ef55b3c4b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [LICENSE]:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 12 items:   8%|â–Š         | 1/12 [00:01<00:13,  1.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9293b250c7943fcb461e8ef642f971b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/13.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aae9963dee54c4b8a88fde14a648678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/10.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 12 items:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:01<00:03,  2.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e2b26e0e9244e28a08a9646da7b548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/9.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e60f68b4814ea185a3aeaea1c3757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [vocab.json]:   0%|          | 0.00/2.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 12 items: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:27<00:00,  2.31s/it]\n",
      "2025-08-14 15:27:35,827 - modelscope - INFO - Download model 'Qwen/Qwen3-1.7B' successfully.\n",
      "2025-08-14 15:27:35,829 - modelscope - INFO - Creating symbolic link [./Qwen/Qwen3-1.7B].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f821e5a9a5b4416080393025786ab102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "# åœ¨modelscopeä¸Šä¸‹è½½Qwenæ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ä¸‹\n",
    "model_dir = snapshot_download(\"Qwen/Qwen3-1.7B\", cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# TransformersåŠ è½½æ¨¡å‹æƒé‡\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Qwen/Qwen3-1.7B\", use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Qwen/Qwen3-1.7B\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec3c672-f8a3-462c-8795-03244c9d7cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T08:25:10.456853Z",
     "iopub.status.busy": "2025-08-14T08:25:10.456539Z",
     "iopub.status.idle": "2025-08-14T08:25:21.705446Z",
     "shell.execute_reply": "2025-08-14T08:25:21.704920Z",
     "shell.execute_reply.started": "2025-08-14T08:25:10.456833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m You can find your API key at: \u001b[33mhttps://swanlab.cn/space/~/settings\u001b[0m\n",
      "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Paste an API key from your profile and hit enter, or press \u001b[32m'CTRL + C'\u001b[0m \n",
      "to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!swanlab login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4d84e0-f506-45d4-92a9-9ebd2517c97d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-15T01:15:41.291351Z",
     "iopub.status.busy": "2025-08-15T01:15:41.290891Z",
     "iopub.status.idle": "2025-08-15T02:32:07.763618Z",
     "shell.execute_reply": "2025-08-15T02:32:07.763093Z",
     "shell.execute_reply.started": "2025-08-15T01:15:41.291332Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Tracking run with swanlab version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Tracking run with swanlab version \u001b[1;36m0.6\u001b[0m.\u001b[1;36m8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Run data will be saved locally in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/mnt/workspace/swanlog/run-20250815_091543-n4nb1emz9pcnw4xeomu4c</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Run data will be saved locally in \u001b[1;35m/mnt/workspace/swanlog/run-20250815_091543-n4nb1emz9pcnw4xeomu4c\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> </span>ğŸ‘‹ Hi <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">csr</span>,welcome to swanlab!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m\u001b[1;34m \u001b[0mğŸ‘‹ Hi \u001b[1;39mcsr\u001b[0m,welcome to swanlab!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Syncing run <span style=\"color: #808000; text-decoration-color: #808000\">rat-2</span> to the cloud\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Syncing run \u001b[33mrat-2\u001b[0m to the cloud\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸ  View project at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@csr/qwen3-sft-medical-LORA</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸ  View project at \u001b[4;34mhttps://swanlab.cn/@csr/qwen3-sft-medical-LORA\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸš€ View run at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@csr/qwen3-sft-medical-LORA/runs/n4nb1emz9pcnw4xeomu4c</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸš€ View run at \u001b[4;34mhttps://swanlab.cn/@csr/qwen3-sft-medical-LORA/runs/n4nb1emz9pcnw4xeomu4c\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@csr/qwen3-sft-medical-LORA/runs/n4nb1emz9pcnw4xeomu4c\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/Qwen/Qwen3-1.7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 09:15:45,842 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc1d96abcec4366932e321381892981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,716,288 || all params: 1,729,291,264 || trainable%: 0.5040\n",
      "åŠ è½½è®­ç»ƒé›†å¹¶è¿›è¡Œé¢„å¤„ç†...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ad1228e31e43c9838eab493edb1059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2166 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½éªŒè¯é›†å¹¶è¿›è¡Œé¢„å¤„ç†...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a56ee0b22042b1824f058b7d158803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-15 09:17:37,036] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:18: DeprecationWarning: The distutils.sysconfig module is deprecated, use sysconfig instead\n",
      "  import distutils.sysconfig\n",
      "df: /root/.triton/autotune: æ²¡æœ‰é‚£ä¸ªæ–‡ä»¶æˆ–ç›®å½•\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-15 09:17:38,953] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹è®­ç»ƒ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1084' max='1084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1084/1084 1:13:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.291200</td>\n",
       "      <td>1.269640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.225200</td>\n",
       "      <td>1.234406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.209800</td>\n",
       "      <td>1.216754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.191600</td>\n",
       "      <td>1.205671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.187800</td>\n",
       "      <td>1.196303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.154500</td>\n",
       "      <td>1.190607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.153700</td>\n",
       "      <td>1.185939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.182542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.122800</td>\n",
       "      <td>1.181476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.128100</td>\n",
       "      <td>1.180115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¿å­˜è®­ç»ƒå¥½çš„LoRAé€‚é…å™¨...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309f04d69c6542e2869c5ce385a8ab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹...\n",
      "\n",
      "            æ ·æœ¬ 1:\n",
      "            é—®é¢˜: 1895å¹´å¾·å›½ç‰©ç†å­¦æ•™æˆä¼¦ç´çš„å‘ç°å¯¹åŒ»å­¦å½±åƒå­¦çš„å‘å±•æœ‰ä½•å…·ä½“å½±å“ï¼Ÿè¯·ä»æŠ€æœ¯è¿›æ­¥ã€å­¦ç§‘å»ºç«‹å’Œä¸´åºŠåº”ç”¨ä¸‰ä¸ªæ–¹é¢è¿›è¡Œåˆ†æã€‚\n",
      "            æ¨¡å‹å›ç­”: <|FunctionCallBegin|>å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯1895å¹´ä¼¦ç´å‘ç°Xå°„çº¿å¯¹åŒ»å­¦å½±åƒå­¦çš„å½±å“ï¼Œéœ€è¦ä»æŠ€æœ¯è¿›æ­¥ã€å­¦ç§‘å»ºç«‹å’Œä¸´åºŠåº”ç”¨ä¸‰ä¸ªæ–¹é¢æ¥åˆ†æã€‚é¦–å…ˆï¼Œæˆ‘å¾—å…ˆå›å¿†ä¸€ä¸‹Xå°„çº¿çš„åŸºæœ¬çŸ¥è¯†ï¼Œä¼¦ç´ç¡®å®æ˜¯åœ¨1895å¹´å‘ç°çš„ï¼Œè¿™å¯èƒ½å°±æ˜¯ç”¨æˆ·æåˆ°çš„é‚£ä¸€å¹´ã€‚ç„¶åï¼Œæˆ‘éœ€è¦åˆ†ä¸‰ä¸ªéƒ¨åˆ†æ¥å±•å¼€æ€è€ƒã€‚\n",
      "\n",
      "é¦–å…ˆï¼ŒæŠ€æœ¯è¿›æ­¥æ–¹é¢ï¼ŒXå°„çº¿æ˜¯ç¬¬ä¸€ç§åŸºäºè¾å°„çš„å½±åƒæŠ€æœ¯ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥è¿™åº”è¯¥ç®—æ˜¯æŠ€æœ¯ä¸Šçš„çªç ´ã€‚ä¹‹å‰å¯èƒ½éƒ½æ˜¯é€šè¿‡å…‰å­¦æ˜¾å¾®é•œæˆ–è€…Xå…‰ç‰‡çš„å…¶ä»–æ–¹æ³•ï¼Œè€ŒXå°„çº¿çš„å‘ç°è®©åŒ»ç”Ÿå¯ä»¥ä¸ç”¨æ˜¾å¾®é•œå°±èƒ½çœ‹åˆ°å†…éƒ¨ç»“æ„ï¼Œè¿™åº”è¯¥æ˜¯æŠ€æœ¯ä¸Šçš„é‡å¤§è¿›å±•ã€‚å¦å¤–ï¼Œå¯èƒ½è¿˜æœ‰åç»­çš„æŠ€æœ¯å‘å±•ï¼Œæ¯”å¦‚Xå°„çº¿çš„è¿›ä¸€æ­¥åº”ç”¨ï¼Œæ¯”å¦‚æ•°å­—å½±åƒä¹‹ç±»çš„ï¼Œä½†ç”¨æˆ·çš„é—®é¢˜å¯èƒ½åªéœ€è¦1895å¹´çš„ç›´æ¥å½±å“ï¼Œæ‰€ä»¥å¯èƒ½ä¸éœ€è¦å¤ªæ·±å…¥åç»­å‘å±•ï¼Œä½†å¾—æåˆ°å®ƒä½œä¸ºåŸºç¡€ã€‚\n",
      "\n",
      "ç„¶åæ˜¯å­¦ç§‘å»ºç«‹æ–¹é¢ï¼Œä¼¦ç´çš„å‘ç°åº”è¯¥ä¿ƒä½¿åŒ»å­¦å½±åƒå­¦æˆä¸ºç‹¬ç«‹å­¦ç§‘ã€‚ä¹‹å‰å¯èƒ½æ›´å¤šæ˜¯è§£å‰–å­¦æˆ–è€…å¤–ç§‘çš„åˆ†æ”¯ï¼Œè€Œå½±åƒå­¦ä½œä¸ºç‹¬ç«‹å­¦ç§‘ï¼Œéœ€è¦ç³»ç»Ÿçš„ç ”ç©¶å’Œç†è®ºå‘å±•ã€‚æ¯”å¦‚ï¼Œå¯èƒ½æˆç«‹äº†ä¸“é—¨çš„åŒ»å­¦å½±åƒå­¦æœºæ„ï¼Œæˆ–è€…åŸ¹å…»ç›¸å…³äººæ‰ï¼Œæ¨åŠ¨ç†è®ºä½“ç³»çš„å»ºç«‹ã€‚å¦å¤–ï¼Œå¯èƒ½è¿˜æœ‰ç›¸å…³å­¦ç§‘å¦‚æ”¾å°„å­¦ã€å†…çª¥é•œç­‰çš„å…´èµ·ï¼Œéƒ½æ˜¯å»ºç«‹åœ¨Xå°„çº¿åŸºç¡€ä¸Šçš„ã€‚\n",
      "\n",
      "ä¸´åºŠåº”ç”¨æ–¹é¢ï¼ŒXå°„çº¿çš„ç›´æ¥åº”ç”¨å°±æ˜¯è¯Šæ–­ç–¾ç—…ï¼Œæ¯”å¦‚éª¨æŠ˜ã€è‚ºç»“èŠ‚ç­‰ã€‚è¿™ä½¿å¾—åŒ»ç”Ÿèƒ½å¤Ÿæ›´æ—©å‘ç°ç–¾ç—…ï¼Œè¿›è¡ŒåŠæ—¶æ²»ç–—ã€‚æ¯”å¦‚ï¼Œè‚ºéƒ¨ç–¾ç—…å¯ä»¥é€šè¿‡Xå…‰æ‹ç‰‡è¯Šæ–­ï¼Œè¿™æ”¹å˜äº†ä¼ ç»Ÿçš„è¯Šæ–­æ–¹æ³•ï¼Œæ¯”å¦‚ä¾èµ–ç—‡çŠ¶å’Œä½“å¾ï¼Œæˆ–è€…éœ€è¦æ‰‹æœ¯æ£€æŸ¥ã€‚æ­¤å¤–ï¼Œå¯èƒ½è¿˜æœ‰åç»­çš„å‘å±•ï¼Œæ¯”å¦‚CTã€MRIç­‰ï¼Œä½†åŒæ ·ï¼Œ1895å¹´çš„å‘ç°ç›´æ¥æ¨åŠ¨äº†è¿™äº›æŠ€æœ¯çš„å‡ºç°ï¼Œä½œä¸ºåŸºç¡€æŠ€æœ¯ã€‚\n",
      "\n",
      "ä¸è¿‡ï¼Œç”¨æˆ·å¯èƒ½éœ€è¦æ›´å…·ä½“çš„ä¾‹å­ï¼Œæ¯”å¦‚åœ¨å­¦ç§‘å»ºç«‹æ–¹é¢ï¼Œä¼¦ç´çš„å·¥ä½œå¦‚ä½•å¼•å‘å…¶ä»–ç§‘å­¦å®¶çš„ç ”ç©¶ï¼Œæ¯”å¦‚åæ¥çš„åŒ»ç”Ÿå’Œç§‘å­¦å®¶å¦‚ä½•å°†Xå°„çº¿åº”ç”¨åˆ°åŒ»å­¦ä¸­ï¼Œå»ºç«‹ç†è®ºï¼Œæˆ–è€…å½¢æˆæ•™å­¦ä½“ç³»ã€‚æ¯”å¦‚ï¼Œå¯èƒ½åœ¨æŸæ—å¤§å­¦è®¾ç«‹åŒ»å­¦å½±åƒå­¦çš„è¯¾ç¨‹ï¼Œæˆ–è€…æœ‰ä¸“é—¨çš„æ•™æå’Œç ”ç©¶æœºæ„ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œä¸´åºŠåº”ç”¨éƒ¨åˆ†ï¼Œé™¤äº†è¯Šæ–­ç–¾ç—…ï¼Œå¯èƒ½è¿˜æœ‰å…¶ä»–åº”ç”¨ï¼Œæ¯”å¦‚æ²»ç–—æ‰‹æ®µï¼Œæ¯”å¦‚Xå°„çº¿å¼•å¯¼ä¸‹çš„æ‰‹æœ¯ï¼Œæˆ–è€…æ²»ç–—æŸäº›ç–¾ç—…ï¼Œä½†å¯èƒ½ä¸»è¦è¿˜æ˜¯è¯Šæ–­ã€‚ä¸è¿‡éœ€è¦ç¡®è®¤è¿™ä¸€ç‚¹æ˜¯å¦å‡†ç¡®ï¼Œæ˜¯å¦æœ‰å…¶ä»–åº”ç”¨ã€‚\n",
      "\n",
      "è¿˜è¦æ³¨æ„æ—¶é—´ç‚¹ï¼Œç”¨æˆ·æ˜ç¡®æåˆ°1895å¹´ï¼Œæ‰€ä»¥éœ€è¦å¼ºè°ƒè¿™æ˜¯ç¬¬ä¸€æ¬¡ï¼Œå…¶ä»–æŠ€æœ¯å¦‚CTã€MRIæ˜¯åœ¨ä¹‹åå‘å±•çš„ï¼Œä½†ä½œä¸ºæŠ€æœ¯è¿›æ­¥çš„åŸºç¡€ã€‚å­¦ç§‘å»ºç«‹æ–¹é¢ï¼Œå¯èƒ½éœ€è¦æåˆ°ä¼¦ç´çš„å·¥ä½œå¦‚ä½•è¢«å…¶ä»–ç§‘å­¦å®¶å‘å±•ï¼Œæ¯”å¦‚åæ¥çš„æ”¾å°„å­¦ä¹‹çˆ¶ï¼Œæˆ–è€…åŒ»å­¦å½±åƒå­¦çš„å¥ åŸºäººï¼Œå¦‚ä½•æ¨åŠ¨å­¦ç§‘å‘å±•ã€‚\n",
      "\n",
      "å¯èƒ½éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„æ–¹é¢ï¼Œæ¯”å¦‚æ˜¯å¦è¿˜æœ‰å…¶ä»–æŠ€æœ¯è¿›æ­¥ï¼Œæ¯”å¦‚Xå°„çº¿çš„æ”¹è¿›ï¼Œæˆ–è€…åç»­çš„è®¾å¤‡å‘å±•ï¼Œä½†é—®é¢˜æ˜ç¡®è¦æ±‚æ˜¯1895å¹´çš„å½±å“ï¼Œæ‰€ä»¥é‡ç‚¹åœ¨é‚£ä¸€å¹´çš„å‘ç°å¸¦æ¥çš„å˜åŒ–ã€‚\n",
      "\n",
      "æ€»ç»“ä¸€ä¸‹ï¼ŒæŠ€æœ¯è¿›æ­¥æ˜¯Xå°„çº¿ä½œä¸ºç¬¬ä¸€ç§æŠ€æœ¯ï¼Œå­¦ç§‘å»ºç«‹æ˜¯ä½œä¸ºç‹¬ç«‹å­¦ç§‘ï¼Œä¸´åºŠåº”ç”¨æ˜¯è¯Šæ–­ç–¾ç—…çš„åº”ç”¨ã€‚éœ€è¦å°†è¿™ä¸‰ä¸ªæ–¹é¢é€ä¸€å±•å¼€ï¼Œæ¯ä¸ªéƒ¨åˆ†ä¸¾å‡ºå…·ä½“çš„ä¾‹å­æˆ–æœºåˆ¶ï¼Œæ¯”å¦‚æŠ€æœ¯ä¸Šå¦‚ä½•æ”¹å˜è¯Šæ–­æ–¹æ³•ï¼Œå­¦ç§‘ä¸Šå¦‚ä½•å½¢æˆç†è®ºä½“ç³»ï¼Œä¸´åºŠåº”ç”¨å¦‚ä½•æ”¹å˜åŒ»ç–—æµç¨‹ç­‰ã€‚\n",
      "<|FunctionCallEnd|> \n",
      " 1895å¹´ï¼Œå¾·å›½ç‰©ç†å­¦æ•™æˆå¨å»‰Â·ä¼¦ç´çš„å‘ç°Xå°„çº¿å¯¹åŒ»å­¦å½±åƒå­¦çš„å‘å±•å…·æœ‰æ·±è¿œçš„å½±å“ã€‚é¦–å…ˆï¼ŒXå°„çº¿çš„å‘ç°ä¸ºåŒ»å­¦å½±åƒå­¦æä¾›äº†æ–°çš„æŠ€æœ¯æ‰‹æ®µï¼Œå®ƒèƒ½å¤Ÿç©¿é€äººä½“ç»„ç»‡ï¼Œæ˜¾ç¤ºå†…éƒ¨ç»“æ„ï¼Œè¿™æå¤§åœ°æé«˜äº†è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚å…¶æ¬¡ï¼Œè¿™ä¸€å‘ç°ä¿ƒè¿›äº†åŒ»å­¦å½±åƒå­¦ä½œä¸ºç‹¬ç«‹å­¦ç§‘çš„å»ºç«‹ï¼Œä¸ºåç»­çš„å½±åƒæŠ€æœ¯å‘å±•å¥ å®šäº†åŸºç¡€ã€‚æœ€åï¼ŒXå°„çº¿çš„åº”ç”¨ä½¿å¾—åŒ»ç”Ÿèƒ½å¤Ÿæ›´æ—©åœ°å‘ç°ç–¾ç—…ï¼Œä»è€Œæ”¹å˜äº†ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—æ–¹æ³•ã€‚\n",
      "            \n",
      "\n",
      "            æ ·æœ¬ 2:\n",
      "            é—®é¢˜: åŒ»ç”Ÿï¼Œæˆ‘æœ€è¿‘èƒƒéƒ¨ä¸é€‚ï¼Œå¬è¯´æœ‰å‡ ç§æŠ—æºƒç–¡è¯ç‰©å¯ä»¥æ²»ç–—ï¼Œæ‚¨èƒ½è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¿™äº›è¯ç‰©çš„åˆ†ç±»ã€ä½œç”¨æœºåˆ¶ä»¥åŠå®ƒä»¬æ˜¯å¦‚ä½•å½±å“èƒƒé»è†œçš„ä¿æŠ¤ä¸æŸä¼¤å¹³è¡¡çš„å—ï¼Ÿ\n",
      "            æ¨¡å‹å›ç­”: <|FunctionCallBegin|>å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯æŠ—æºƒç–¡è¯ç‰©çš„åˆ†ç±»ã€ä½œç”¨æœºåˆ¶ä»¥åŠå®ƒä»¬å¦‚ä½•å½±å“èƒƒé»è†œçš„ä¿æŠ¤ä¸æŸä¼¤å¹³è¡¡ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦å›å¿†ä¸€ä¸‹å¸¸è§çš„æŠ—æºƒç–¡è¯ç‰©ï¼Œè®°å¾—åˆ†ç±»çš„è¯å¯èƒ½åˆ†ä¸ºè´¨å­æ³µæŠ‘åˆ¶å‰‚ã€H2å—ä½“æ‹®æŠ—å‰‚ã€é»è†œä¿æŠ¤å‰‚å’Œä¿ƒåŠ¨åŠ›è¯è¿™äº›ç±»åˆ«ã€‚ç„¶åæ¯ä¸ªç±»åˆ«é‡Œæœ‰å“ªäº›å…·ä½“çš„è¯ç‰©å‘¢ï¼Ÿ\n",
      "\n",
      "è´¨å­æ³µæŠ‘åˆ¶å‰‚ï¼Œæ¯”å¦‚å¥¥ç¾æ‹‰å”‘ï¼Œæ˜¯é€šè¿‡æŠ‘åˆ¶è´¨å­æ³µæ¥å‡å°‘èƒƒé…¸åˆ†æ³Œçš„ï¼Œæ‰€ä»¥åº”è¯¥å±äºé…¸åˆ†æ³ŒæŠ‘åˆ¶å‰‚ã€‚H2å—ä½“æ‹®æŠ—å‰‚ï¼Œæ¯”å¦‚é›·å°¼æ›¿ä¸ï¼Œæ˜¯é˜»æ­¢ç»„èƒºä¸H2å—ä½“ç»“åˆï¼Œå‡å°‘èƒƒé…¸ã€‚é»è†œä¿æŠ¤å‰‚æ¯”å¦‚ç¡«ç³–é“ï¼Œå¯èƒ½ä¿ƒè¿›é»æ¶²åˆ†æ³Œæˆ–è€…å½¢æˆä¿æŠ¤å±‚ã€‚ä¿ƒåŠ¨åŠ›è¯æ¯”å¦‚å¤šæ½˜ç«‹é…®ï¼Œåˆºæ¿€èƒƒè •åŠ¨ï¼Œå‡å°‘èƒƒé…¸åˆ†æ³Œæˆ–è€…ä¿ƒè¿›æ’ç©ºï¼Ÿ\n",
      "\n",
      "æ¥ä¸‹æ¥è¦è§£é‡Šæ¯ä¸ªç±»åˆ«çš„ä½œç”¨æœºåˆ¶ã€‚æ¯”å¦‚è´¨å­æ³µæŠ‘åˆ¶å‰‚çš„ä½œç”¨æœºåˆ¶æ˜¯ç›´æ¥æŠ‘åˆ¶è´¨å­æ³µï¼Œå‡å°‘HClçš„åˆ†æ³Œï¼Œä»è€Œé™ä½èƒƒé…¸ï¼Œä¿æŠ¤é»è†œã€‚H2å—ä½“æ‹®æŠ—å‰‚é€šè¿‡é˜»æ–­ç»„èƒºçš„ä½œç”¨ï¼ŒåŒæ ·å‡å°‘èƒƒé…¸ã€‚é»è†œä¿æŠ¤å‰‚å¯èƒ½ä¿ƒè¿›é»æ¶²çš„ç”Ÿæˆæˆ–è€…å½¢æˆä¿æŠ¤å±éšœï¼Œæ¯”å¦‚ç¡«ç³–é“å¯èƒ½ä¿ƒè¿›é»æ¶²åˆ†æ³Œï¼Œå½¢æˆä¿æŠ¤å±‚ï¼ŒåŒæ—¶ä¸­å’Œèƒƒé…¸ã€‚ä¿ƒåŠ¨åŠ›è¯é€šè¿‡åŠ å¿«èƒƒæ’ç©ºï¼Œå‡å°‘èƒƒé…¸åæµçš„æœºä¼šã€‚\n",
      "\n",
      "ç„¶åè¦è€ƒè™‘è¿™äº›è¯ç‰©å¦‚ä½•å½±å“èƒƒé»è†œçš„ä¿æŠ¤ä¸æŸä¼¤å¹³è¡¡ã€‚æ¯”å¦‚ï¼Œå¦‚æœèƒƒé…¸è¿‡å¤šï¼Œè¿™äº›è¯ç‰©é€šè¿‡æŠ‘åˆ¶é…¸åˆ†æ³Œï¼Œå¸®åŠ©æ¢å¤é»è†œçš„ä¿æŠ¤çŠ¶æ€ã€‚å¦‚æœé»è†œæœ¬èº«æœ‰æŸä¼¤ï¼Œä¿æŠ¤å‰‚å¯èƒ½å¸®åŠ©ä¿®å¤ï¼Œä½†å¦‚æœæœ‰æŒç»­æŸä¼¤ï¼Œå¯èƒ½éœ€è¦å…¶ä»–è¯ç‰©ã€‚ä¿ƒåŠ¨åŠ›è¯å¯èƒ½å¸®åŠ©å‡å°‘èƒƒå†…å®¹ç‰©æ»ç•™ï¼Œå‡å°‘å¯¹é»è†œçš„åˆºæ¿€ï¼Ÿ\n",
      "\n",
      "ç”¨æˆ·æåˆ°è‡ªå·±èƒƒéƒ¨ä¸é€‚ï¼Œå¯èƒ½éœ€è¦æ ¹æ®ç—‡çŠ¶é€‰æ‹©åˆé€‚çš„è¯ç‰©ã€‚æ¯”å¦‚å¦‚æœç—‡çŠ¶æ˜¯èƒƒé…¸è¿‡å¤šï¼Œå¯èƒ½è´¨å­æ³µæŠ‘åˆ¶å‰‚æ›´æœ‰æ•ˆï¼›å¦‚æœç—‡çŠ¶æ˜¯åé…¸æˆ–èƒƒèƒ€ï¼Œå¯èƒ½ä¿ƒåŠ¨åŠ›è¯ã€‚ä½†éœ€è¦æé†’ç”¨æˆ·ä¸èƒ½è‡ªè¡Œç”¨è¯ï¼Œå¿…é¡»éµåŒ»å˜±ã€‚\n",
      "\n",
      "æœ‰æ²¡æœ‰é—æ¼çš„åˆ†ç±»ï¼Ÿæ¯”å¦‚è¿˜æœ‰æŠ—é…¸å‰‚ï¼Œæ¯”å¦‚é“ç¢³é…¸é•ï¼Œå¯èƒ½å±äºé»è†œä¿æŠ¤å‰‚çš„ä¸€ç§ï¼Ÿæˆ–è€…æ˜¯å¦åº”è¯¥åŒ…æ‹¬å…¶ä»–ç±»åˆ«ï¼Ÿæ¯”å¦‚H2å—ä½“æ‹®æŠ—å‰‚å’Œé»è†œä¿æŠ¤å‰‚å¯èƒ½å±äºä¸åŒçš„æœºåˆ¶ï¼Œä½†åˆ†ç±»å¯èƒ½éœ€è¦æ›´æ˜ç¡®ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œä½œç”¨æœºåˆ¶éƒ¨åˆ†æ˜¯å¦éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Ÿæ¯”å¦‚è´¨å­æ³µæŠ‘åˆ¶å‰‚çš„ä½œç”¨é¶ç‚¹ï¼ŒH2å—ä½“æ‹®æŠ—å‰‚çš„ä½œç”¨é¶ç‚¹ï¼Œé»è†œä¿æŠ¤å‰‚çš„æœºåˆ¶ï¼Œæ¯”å¦‚ä¸­å’Œé…¸ã€ä¿ƒè¿›é»æ¶²ç”Ÿæˆç­‰ã€‚ä¿ƒåŠ¨åŠ›è¯çš„ä½œç”¨æ˜¯å¢åŠ èƒƒæ’ç©ºï¼Œå‡å°‘èƒƒé…¸åæµæˆ–å‡å°‘èƒƒå†…å®¹ç‰©å¯¹é»è†œçš„ç›´æ¥æ¥è§¦ã€‚\n",
      "\n",
      "å¯èƒ½è¿˜éœ€è¦æåˆ°è¿™äº›è¯ç‰©çš„ååŒä½œç”¨ï¼Œæ¯”å¦‚åŒæ—¶ä½¿ç”¨H2å—ä½“æ‹®æŠ—å‰‚å’Œé»è†œä¿æŠ¤å‰‚å¯èƒ½æ›´æœ‰æ•ˆã€‚ä½†ç”¨æˆ·çš„é—®é¢˜å¯èƒ½ä¸éœ€è¦è¿™ä¹ˆæ·±å…¥ï¼Œä½†ä½œä¸ºå›ç­”çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥ç®€è¦æåŠã€‚\n",
      "\n",
      "æœ€åï¼Œç¡®ä¿è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé¿å…ä¸“ä¸šæœ¯è¯­è¿‡å¤šï¼Œä½†ç”¨æˆ·æ˜¯åŒ»ç”Ÿï¼Œå¯èƒ½éœ€è¦ç¨å¾®ä¸“ä¸šä¸€ç‚¹ï¼Œä½†é—®é¢˜ä¸­çš„ç”¨æˆ·æ˜¯æ‚£è€…ï¼Œæ‰€ä»¥éœ€è¦è§£é‡Šæ¸…æ¥šã€‚æ¯”å¦‚ç¡«ç³–é“çš„ä½œç”¨æœºåˆ¶æ˜¯ä¿ƒè¿›é»æ¶²åˆ†æ³Œï¼Œå½¢æˆä¿æŠ¤å±‚ï¼ŒåŒæ—¶ä¸­å’Œèƒƒé…¸ï¼Œå‡å°‘åˆºæ¿€ã€‚\n",
      "\n",
      "æ€»ç»“ä¸‹æ¥ï¼Œç»“æ„åº”è¯¥æ˜¯å…ˆåˆ†ç±»ï¼Œæ¯ä¸ªç±»åˆ«ä¸¾ä¾‹å­ï¼Œç„¶åè¯´æ˜æ¯ä¸ªè¯ç‰©çš„ä½œç”¨æœºåˆ¶ï¼Œæœ€åè®²å®ƒä»¬å¦‚ä½•å½±å“é»è†œçš„ä¿æŠ¤ä¸æŸä¼¤å¹³è¡¡ã€‚å¯èƒ½è¿˜è¦æåˆ°ä¸åŒè¯ç‰©çš„é€‚ç”¨æƒ…å†µï¼Œæ¯”å¦‚èƒƒé…¸è¿‡å¤šç”¨PPIsï¼Œåé…¸ç”¨H2å—ä½“æ‹®æŠ—å‰‚ï¼Œé»è†œä¿æŠ¤ç”¨ç¡«ç³–é“ï¼Œä¿ƒåŠ¨åŠ›ç”¨å¤šæ½˜ç«‹é…®ã€‚ä½†éœ€è¦æ ¹æ®é—®é¢˜ä¸­çš„ç­”æ¡ˆæ¥ç»„ç»‡ï¼Œç­”æ¡ˆé‡Œå·²ç»æåˆ°è¿™äº›è¯ç‰©çš„åˆ†ç±»å’Œä½œç”¨æœºåˆ¶ï¼Œæ‰€ä»¥éœ€è¦æŒ‰ç…§ç­”æ¡ˆçš„ç»“æ„æ¥ç»„ç»‡æ€è€ƒè¿‡ç¨‹ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰è¦ç‚¹ã€‚\n",
      "<|FunctionCallEnd|> \n",
      " å½“ç„¶å¯ä»¥ã€‚æŠ—æºƒç–¡è¯ç‰©ä¸»è¦åˆ†ä¸ºå‡ å¤§ç±»ï¼Œæ¯ç§è¯ç‰©éƒ½æœ‰å…¶ç‰¹å®šçš„ä½œç”¨æœºåˆ¶å’Œä½¿ç”¨èŒƒå›´ã€‚ç¬¬ä¸€ç±»æ˜¯é…¸åˆ†æ³ŒæŠ‘åˆ¶å‰‚ï¼Œè¿™ç±»è¯ç‰©é€šè¿‡æŠ‘åˆ¶èƒƒé…¸çš„åˆ†æ³Œæ¥æ²»ç–—èƒƒæºƒç–¡ã€‚ä¾‹å¦‚ï¼Œå¥¥ç¾æ‹‰å”‘æ˜¯ä¸€ç§è´¨å­æ³µæŠ‘åˆ¶å‰‚ï¼Œå®ƒèƒ½æœ‰æ•ˆæŠ‘åˆ¶èƒƒé…¸çš„åˆ†æ³Œï¼Œä»è€Œå‡å°‘èƒƒé…¸å¯¹èƒƒé»è†œçš„åˆºæ¿€ã€‚ç¬¬äºŒç±»æ˜¯H2å—ä½“æ‹®æŠ—å‰‚ï¼Œå®ƒä»¬é€šè¿‡é˜»æ–­èƒƒé…¸åˆ†æ³Œè¿‡ç¨‹ä¸­çš„å…³é”®æ­¥éª¤æ¥å‡å°‘èƒƒé…¸ï¼Œæ¯”å¦‚é›·å°¼æ›¿ä¸ã€‚ç¬¬ä¸‰ç±»æ˜¯é»è†œä¿æŠ¤å‰‚ï¼Œè¿™ç±»è¯ç‰©èƒ½ä¿ƒè¿›èƒƒé»è†œçš„ä¿®å¤ï¼Œä¾‹å¦‚ç¡«ç³–é“ï¼Œå®ƒæœ‰åŠ©äºå½¢æˆä¸€å±‚ä¿æŠ¤æ€§çš„é»è†œå±éšœï¼Œå‡å°‘èƒƒé…¸å¯¹é»è†œçš„æŸä¼¤ã€‚ç¬¬å››ç±»æ˜¯ä¿ƒåŠ¨åŠ›è¯ï¼Œè¿™ç±»è¯ç‰©é€šè¿‡åˆºæ¿€èƒƒéƒ¨è •åŠ¨ï¼Œå¸®åŠ©èƒƒå†…å®¹ç‰©æ›´å¿«åœ°æ’å‡ºï¼Œå‡å°‘èƒƒé…¸åæµçš„å¯èƒ½æ€§ï¼Œå¦‚å¤šæ½˜ç«‹é…®ã€‚æ¯ç§è¯ç‰©éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æ²»ç–—æ•ˆæœï¼ŒåŒ»ç”Ÿä¼šæ ¹æ®æ‚¨çš„å…·ä½“ç—…æƒ…é€‰æ‹©æœ€åˆé€‚çš„è¯ç‰©ã€‚\n",
      "            \n",
      "\n",
      "            æ ·æœ¬ 3:\n",
      "            é—®é¢˜: æˆ‘æœ€è¿‘è¢«è¯Šæ–­å‡ºæ‚£æœ‰æ·‹å·´ç˜¤ï¼ŒåŒ»ç”Ÿæåˆ°è¿™å¯èƒ½å¯¼è‡´å‘çƒ­ã€‚è¯·é—®è¿™æ˜¯ç”±äºæ·‹å·´ç˜¤ç»„ç»‡çš„åæ­»å’Œç»†èƒç ´åå¼•èµ·çš„å—ï¼Ÿå¦‚æœæ˜¯ï¼Œå…·ä½“æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "            æ¨¡å‹å›ç­”: <|FunctionCallBegin|>å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯æ·‹å·´ç˜¤ç»„ç»‡åæ­»å’Œç»†èƒç ´åæ˜¯å¦ä¼šå¯¼è‡´å‘çƒ­ï¼Œä»¥åŠå…·ä½“æœºåˆ¶æ˜¯ä»€ä¹ˆã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦å›å¿†ä¸€ä¸‹æ·‹å·´ç˜¤çš„åŸºæœ¬çŸ¥è¯†ã€‚æ·‹å·´ç˜¤æ˜¯èµ·æºäºæ·‹å·´ç³»ç»Ÿçš„æ¶æ€§è‚¿ç˜¤ï¼Œé€šå¸¸åˆ†ä¸ºBç»†èƒå’ŒTç»†èƒæ·‹å·´ç˜¤ã€‚åæ­»å¯èƒ½æ˜¯å› ä¸ºè‚¿ç˜¤ç»„ç»‡ç”Ÿé•¿è¿…é€Ÿï¼Œå¯¼è‡´å‘¨å›´ç»„ç»‡çš„ç ´åï¼Œè¿›è€Œå¼•å‘ç‚ç—‡ååº”ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œå‘çƒ­é€šå¸¸ç”±æ„ŸæŸ“æˆ–ç‚ç—‡å¼•èµ·ï¼Œä½†æ·‹å·´ç˜¤æ‚£è€…å¸¸è§çš„å‘çƒ­åŸå› å¯èƒ½åŒ…æ‹¬æ„ŸæŸ“ã€è‚¿ç˜¤æœ¬èº«å¯¼è‡´çš„ç‚ç—‡ååº”ï¼Œæˆ–è€…è‚¿ç˜¤åæ­»é‡Šæ”¾çš„ç‰©è´¨ã€‚åæ­»ç»„ç»‡é‡Šæ”¾çš„ç»†èƒå› å­ï¼Œæ¯”å¦‚TNF-Î±ã€IL-6ç­‰ï¼Œè¿™äº›ç‰©è´¨ä¼šå¼•å‘ç‚ç—‡ååº”ï¼Œå¯¼è‡´å‘çƒ­ã€‚åŒæ—¶ï¼Œåæ­»ç»„ç»‡æœ¬èº«ä¹Ÿå¯èƒ½ç›´æ¥åˆºæ¿€å…ç–«ç³»ç»Ÿï¼Œå¯¼è‡´å‘çƒ­ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œç»†èƒç ´åå¯èƒ½æ¶‰åŠè‚¿ç˜¤ç»†èƒçš„æ­»äº¡ï¼Œé‡Šæ”¾ç»†èƒå†…å®¹ç‰©ï¼Œè¿™äº›ç‰©è´¨åŒæ ·å¯ä»¥å¼•å‘ç‚ç—‡å’Œå‘çƒ­ã€‚è¿˜æœ‰å¯èƒ½è‚¿ç˜¤åæ­»å¯¼è‡´å±€éƒ¨ç»„ç»‡çš„ç›´æ¥åˆºæ¿€ï¼Œæ¯”å¦‚é‡Šæ”¾çš„è›‹ç™½é…¶æˆ–å…¶ä»–ä»‹è´¨ï¼Œå¯¼è‡´å‘¨å›´ç»„ç»‡ååº”ã€‚\n",
      "\n",
      "éœ€è¦ç¡®è®¤è¿™äº›æœºåˆ¶æ˜¯å¦æ­£ç¡®ã€‚æ¯”å¦‚ï¼ŒTNF-Î±ç¡®å®ä¸ç‚ç—‡ååº”ç›¸å…³ï¼Œè€Œç»†èƒå› å­çš„é‡Šæ”¾ç¡®å®ä¼šå¯¼è‡´å‘çƒ­ã€‚æ­¤å¤–ï¼Œæ„ŸæŸ“æ€§å‘çƒ­å’Œè‚¿ç˜¤åæ­»éƒ½å±äºéæ„ŸæŸ“æ€§å‘çƒ­çš„åŸå› ä¹‹ä¸€ï¼Œæ‰€ä»¥ä¸¤è€…éƒ½éœ€è¦è€ƒè™‘ã€‚\n",
      "\n",
      "ç”¨æˆ·æåˆ°åŒ»ç”Ÿè¯´å¯èƒ½å¼•èµ·å‘çƒ­ï¼Œæ‰€ä»¥éœ€è¦è§£é‡Šæœºåˆ¶æ—¶è¦å…·ä½“åˆ°åæ­»å’Œç»†èƒç ´åã€‚å¯èƒ½è¿˜è¦æåˆ°æ²»ç–—ä¸Šçš„å»ºè®®ï¼Œæ¯”å¦‚æŠ—æ„ŸæŸ“ã€é€€çƒ§è¯ç‰©ï¼Œä½†ç”¨æˆ·çš„é—®é¢˜ä¸»è¦å…³æ³¨æœºåˆ¶ï¼Œæ‰€ä»¥é‡ç‚¹æ”¾åœ¨åæ­»å’Œç»†èƒç ´åçš„ä½œç”¨ä¸Šã€‚\n",
      "\n",
      "æœ‰æ²¡æœ‰å¯èƒ½é—æ¼äº†å…¶ä»–æœºåˆ¶ï¼Ÿæ¯”å¦‚ï¼Œæ·‹å·´ç˜¤ç»†èƒæœ¬èº«åæ­»é‡Šæ”¾çš„ç»†èƒå› å­ï¼Œæˆ–è€…åæ­»ç»„ç»‡ä¸­çš„ç»†èŒæ„ŸæŸ“ï¼Ÿä¸è¿‡é€šå¸¸å‘çƒ­æ›´å¤šæ˜¯ç”±äºç‚ç—‡ä»‹è´¨è€Œéç»†èŒæ„ŸæŸ“ã€‚éœ€è¦æ˜ç¡®å›ç­”æ˜¯åæ­»ç»„ç»‡æœ¬èº«çš„ç»†èƒå› å­å’Œç‚ç—‡ååº”ï¼Œè€Œä¸æ˜¯æ„ŸæŸ“ã€‚\n",
      "\n",
      "æ€»ç»“ä¸‹æ¥ï¼Œç­”æ¡ˆåº”è¯¥åŒ…æ‹¬ï¼šæ˜¯çš„ï¼Œåæ­»å¯¼è‡´ç‚ç—‡å› å­é‡Šæ”¾ï¼Œå¼•å‘å‘çƒ­ï¼›å…·ä½“æœºåˆ¶æ˜¯åæ­»ç»„ç»‡é‡Šæ”¾ç»†èƒå› å­å¦‚TNF-Î±ã€IL-6ï¼Œå¯¼è‡´ç‚ç—‡ååº”å’Œå‘çƒ­ã€‚åŒæ—¶ï¼Œæ²»ç–—å¯èƒ½åŒ…æ‹¬é€€çƒ§è¯ç‰©å’Œæ§åˆ¶æ„ŸæŸ“ã€‚éœ€è¦ç¡®ä¿è¿™äº›ä¿¡æ¯å‡†ç¡®ï¼Œå¹¶ä¸”ç”¨é€šä¿—çš„è¯­è¨€è§£é‡Šï¼Œè®©ç”¨æˆ·ç†è§£åŸå› ã€‚\n",
      "<|FunctionCallEnd|> \n",
      " æ˜¯çš„ï¼Œæ‚¨çš„æƒ…å†µå¯èƒ½æ˜¯ç”±äºæ·‹å·´ç˜¤ç»„ç»‡çš„åæ­»å’Œç»†èƒç ´åå¼•èµ·çš„å‘çƒ­ã€‚è¿™ç§å‘çƒ­é€šå¸¸æ˜¯å› ä¸ºè‚¿ç˜¤ç»„ç»‡å†…çš„ç»†èƒè¢«ç ´ååé‡Šæ”¾çš„ç‚ç—‡ä»‹è´¨ï¼Œå¦‚ç»†èƒå› å­ç­‰ï¼Œå¯¼è‡´å±€éƒ¨æˆ–å…¨èº«çš„ç‚ç—‡ååº”ã€‚è¿™äº›ç‚ç—‡ä»‹è´¨å¯ä»¥æ¿€æ´»å…ç–«ç³»ç»Ÿï¼Œå¼•å‘å‘çƒ­ã€‚å»ºè®®æ‚¨ä¿æŒè‰¯å¥½çš„ä¼‘æ¯å’Œé¥®é£Ÿï¼Œå¿…è¦æ—¶ä½¿ç”¨é€€çƒ§è¯ç‰©ã€‚å¦‚æœæœ‰å‘çƒ­çš„æƒ…å†µï¼ŒåŠæ—¶ä¸åŒ»ç”Ÿæ²Ÿé€šï¼Œä»¥ä¾¿é‡‡å–é€‚å½“çš„æ²»ç–—æªæ–½ã€‚\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸ  View project at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@csr/qwen3-sft-medical-LORA</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸ  View project at \u001b[4;34mhttps://swanlab.cn/@csr/qwen3-sft-medical-LORA\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸš€ View run at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@csr/qwen3-sft-medical-LORA/runs/n4nb1emz9pcnw4xeomu4c</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸš€ View run at \u001b[4;34mhttps://swanlab.cn/@csr/qwen3-sft-medical-LORA/runs/n4nb1emz9pcnw4xeomu4c\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import swanlab\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "\n",
    "# é…ç½®é¡¹ç›®å‚æ•°\n",
    "os.environ[\"SWANLAB_PROJECT\"] = \"qwen3-sft-medical-LORA\" \n",
    "PROMPT = \"ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¸“å®¶ï¼Œä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºå¸¦æœ‰æ€è€ƒçš„å›ç­”ã€‚\"\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "# é…ç½®swanlabå®éªŒå‚æ•°\n",
    "run = swanlab.init(\n",
    "    project=os.environ[\"SWANLAB_PROJECT\"],\n",
    "    config={\n",
    "    \"model\": \"Qwen/Qwen3-1.7B-LoRA\", \n",
    "    \"prompt\": PROMPT,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "    \"lora_r\": 8, \n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"\n",
    "    å°†åŸå§‹JSONLæ•°æ®é›†è½¬æ¢ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰€éœ€çš„æ ¼å¼\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                output = f\"<|FunctionCallBegin|>{data['think']}<|FunctionCallEnd|> \\n {data['answer']}\"\n",
    "                message = {\n",
    "                    \"instruction\": PROMPT,\n",
    "                    \"input\": data[\"question\"],\n",
    "                    \"output\": output\n",
    "                }\n",
    "                messages.append(message)\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}, è¡Œå†…å®¹: {line}\")\n",
    "                \n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    é¢„å¤„ç†å‡½æ•°ï¼šå°†æ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "    \"\"\"\n",
    "    # æ„å»ºç³»ç»Ÿæç¤ºå’Œç”¨æˆ·è¾“å…¥éƒ¨åˆ†\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n{PROMPT}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    \n",
    "    # æ„å»ºæ¨¡å‹å›åº”éƒ¨åˆ†\n",
    "    response = tokenizer(\n",
    "        f\"{example['output']}\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    \n",
    "    # åˆå¹¶è¾“å…¥å’Œè¾“å‡ºï¼Œæ·»åŠ ç»“æŸæ ‡è®°\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    # labelsä¸­å¯¹è¾“å…¥éƒ¨åˆ†ä½¿ç”¨-100è¡¨ç¤ºä¸å‚ä¸æŸå¤±è®¡ç®—\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    \n",
    "    # æˆªæ–­è¿‡é•¿åºåˆ—\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    \"\"\"\n",
    "    é¢„æµ‹å‡½æ•°ï¼šæ ¹æ®è¾“å…¥æ¶ˆæ¯ç”Ÿæˆæ¨¡å‹å›åº”\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # åº”ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–è¾“å…¥\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # ç”Ÿæˆå›åº”\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "        temperature=0.7,  # æ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    # æå–ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆæ’é™¤è¾“å…¥éƒ¨åˆ†ï¼‰\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    # è§£ç ä¸ºæ–‡æœ¬\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response\n",
    "\n",
    "# ä¸»ç¨‹åºæ‰§è¡Œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ï¼‰\n",
    "    model_dir = snapshot_download(\n",
    "        \"Qwen/Qwen3-1.7B\",\n",
    "        cache_dir=\"/mnt/workspace\",\n",
    "        revision=\"master\"\n",
    "    )\n",
    "    \n",
    "    # åŠ è½½tokenizerå’Œæ¨¡å‹\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir,\n",
    "        use_fast=False,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # å¯¹äºLoRAå¾®è°ƒï¼Œå¦‚æœæ¨¡å‹æœ¬èº«æ²¡æœ‰pad_tokenï¼Œæ˜¾å¼æŒ‡å®šä¸€ä¸ª\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ‰€éœ€é…ç½® \n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    # ==================== é…ç½®å’Œåº”ç”¨LoRA ====================\n",
    "    # 1. å®šä¹‰LoRAé…ç½®\n",
    "    config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,  # ä»»åŠ¡ç±»å‹ï¼šå› æœè¯­è¨€æ¨¡å‹\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # æŒ‡å®šè¦åº”ç”¨LoRAçš„æ¨¡å—\n",
    "        r=8,                           # LoRAçš„ç§©ï¼Œå¸¸ç”¨8, 16, 32ã€‚è¶Šå°å‚æ•°è¶Šå°‘\n",
    "        lora_alpha=16,                 # LoRAçš„ç¼©æ”¾å› å­ï¼Œé€šå¸¸æ˜¯rçš„ä¸¤å€\n",
    "        lora_dropout=0.1,              # Dropoutæ¯”ä¾‹\n",
    "    )\n",
    "\n",
    "    # 2. ä½¿ç”¨get_peft_modelå°†åŸºç¡€æ¨¡å‹åŒ…è£…ä¸ºPEFTæ¨¡å‹\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    # 3. æ‰“å°å¯è®­ç»ƒå‚æ•°çš„æ•°é‡å’Œæ¯”ä¾‹ï¼Œä»¥ç¡®è®¤LoRAç”Ÿæ•ˆ\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    # æ•°æ®é›†è·¯å¾„é…ç½® \n",
    "    train_dataset_path = \"train.jsonl\"\n",
    "    test_dataset_path = \"val.jsonl\"\n",
    "    train_jsonl_new_path = \"train_format.jsonl\"\n",
    "    test_jsonl_new_path = \"val_format.jsonl\"\n",
    "    \n",
    "    # è½¬æ¢æ•°æ®é›†æ ¼å¼ \n",
    "    if not os.path.exists(train_jsonl_new_path):\n",
    "        print(f\"è½¬æ¢è®­ç»ƒé›†: {train_dataset_path} -> {train_jsonl_new_path}\")\n",
    "        dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "    \n",
    "    if not os.path.exists(test_jsonl_new_path):\n",
    "        print(f\"è½¬æ¢éªŒè¯é›†: {test_dataset_path} -> {test_jsonl_new_path}\")\n",
    "        dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)\n",
    "    \n",
    "    # åŠ è½½å¹¶é¢„å¤„ç†è®­ç»ƒé›† \n",
    "    print(\"åŠ è½½è®­ç»ƒé›†å¹¶è¿›è¡Œé¢„å¤„ç†...\")\n",
    "    train_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "    \n",
    "    # åŠ è½½å¹¶é¢„å¤„ç†éªŒè¯é›†\n",
    "    print(\"åŠ è½½éªŒè¯é›†å¹¶è¿›è¡Œé¢„å¤„ç†...\")\n",
    "    eval_df = pd.read_json(test_jsonl_new_path, lines=True)\n",
    "    eval_ds = Dataset.from_pandas(eval_df)\n",
    "    eval_dataset = eval_ds.map(process_func, remove_columns=eval_ds.column_names)\n",
    "    \n",
    "    # é…ç½®è®­ç»ƒå‚æ•°\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"/mnt/workspace/Qwen3-1.7B-LoRA\", \n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=4,\n",
    "        save_steps=400,\n",
    "        learning_rate=5e-5,\n",
    "        save_on_each_node=True,\n",
    "        gradient_checkpointing=True,\n",
    "        report_to=\"swanlab\",\n",
    "        run_name=\"qwen3-1.7B-medical-lora\",\n",
    "        bf16=True,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "    )\n",
    "\n",
    "    # åˆå§‹åŒ–Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    "    )\n",
    "\n",
    "    # å¼€å§‹è®­ç»ƒ\n",
    "    print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    # å¯¹äºPEFTæ¨¡å‹ï¼Œåªä¿å­˜é€‚é…å™¨éƒ¨åˆ†\n",
    "    print(\"ä¿å­˜è®­ç»ƒå¥½çš„LoRAé€‚é…å™¨...\")\n",
    "    final_lora_path = os.path.join(training_args.output_dir, \"final_lora_adapter\")\n",
    "    trainer.model.save_pretrained(final_lora_path)\n",
    "    # åŒæ—¶ä¹Ÿå¯ä»¥ä¿å­˜tokenizer\n",
    "    tokenizer.save_pretrained(final_lora_path)\n",
    "\n",
    "    # ==================== é¢„æµ‹å‰éœ€è¦åˆå¹¶æ¨¡å‹ ====================\n",
    "    # åœ¨è¿›è¡Œé¢„æµ‹æˆ–éƒ¨ç½²æ—¶ï¼Œéœ€è¦å°†LoRAæƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶\n",
    "    from peft import PeftModel\n",
    "    # é‡æ–°åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    # åŠ è½½LoRAé€‚é…å™¨å¹¶ä¸åŸºç¡€æ¨¡å‹åˆå¹¶\n",
    "    model = PeftModel.from_pretrained(base_model, final_lora_path)\n",
    "    model = model.merge_and_unload() # åˆå¹¶æƒé‡\n",
    "    \n",
    "\n",
    "    # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹å¹¶è®°å½•ç»“æœ\n",
    "    print(\"åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹...\")\n",
    "    test_df = pd.read_json(test_jsonl_new_path, lines=True)[:3]  # å–å‰3æ¡æµ‹è¯•\n",
    "    test_text_list = []\n",
    "    \n",
    "    for index, row in test_df.iterrows():\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": row['instruction']},\n",
    "            {\"role\": \"user\", \"content\": row['input']}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = predict(messages, model, tokenizer)\n",
    "            response_text = f\"\"\"\n",
    "            æ ·æœ¬ {index + 1}:\n",
    "            é—®é¢˜: {row['input']}\n",
    "            æ¨¡å‹å›ç­”: {response}\n",
    "            \"\"\"\n",
    "            print(response_text)\n",
    "            test_text_list.append(swanlab.Text(response_text))\n",
    "        except Exception as e:\n",
    "            print(f\"é¢„æµ‹æ ·æœ¬ {index + 1} æ—¶å‡ºé”™: {e}\")\n",
    "    \n",
    "    # è®°å½•é¢„æµ‹ç»“æœåˆ°swanlab\n",
    "    swanlab.log({\"é¢„æµ‹ç»“æœ\": test_text_list})\n",
    "    swanlab.finish()\n",
    "    print(\"è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c579dd-c2db-4ad4-ae04-12e8f69ed8fa",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-08-15T02:44:07.966667Z",
     "iopub.status.busy": "2025-08-15T02:44:07.966398Z",
     "iopub.status.idle": "2025-08-15T03:10:40.183901Z",
     "shell.execute_reply": "2025-08-15T03:10:40.183246Z",
     "shell.execute_reply.started": "2025-08-15T02:44:07.966651Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc397df8c93d4490b63f757c16013f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›ç­”ï¼š<|FunctionCallBegin|>å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯å¤´ç—›çš„å¸¸è§åŸå› æœ‰å“ªäº›ï¼Œä»¥åŠå¦‚ä½•æ ¹æ®ä¸åŒçš„åŸå› é€‰æ‹©åˆé€‚çš„è¯ç‰©ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦å›å¿†ä¸€ä¸‹å¸¸è§çš„å¤´ç—›ç±»å‹ï¼Œæ¯”å¦‚ç´§å¼ æ€§å¤´ç—›ã€åå¤´ç—›ã€ä¸›é›†æ€§å¤´ç—›ï¼Œè¿˜æœ‰å…¶ä»–ç±»å‹æ¯”å¦‚è¡€ç®¡æ€§å¤´ç—›æˆ–è€…é¢…å†…å‹å¢é«˜å¼•èµ·çš„ã€‚ç„¶åï¼Œé’ˆå¯¹æ¯ç§å¤´ç—›ç±»å‹ï¼Œå¸¸è§çš„æ²»ç–—æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Œè¯ç‰©ä¸Šæœ‰ä»€ä¹ˆåŒºåˆ«ã€‚\n",
      "\n",
      "ç”¨æˆ·è¿˜æåˆ°è‡ªå·±å¤´ç—›å‰å®³ï¼Œæƒ³çŸ¥é“åƒä»€ä¹ˆè¯ï¼Œæ‰€ä»¥å¯èƒ½éœ€è¦å…ˆåˆ¤æ–­å¤´ç—›çš„åŸå› ï¼Œå†ç»™å‡ºå»ºè®®ã€‚ä½†ç”¨æˆ·å¯èƒ½ä¸å¤ªæ¸…æ¥šç—‡çŠ¶çš„å…·ä½“æƒ…å†µï¼Œæ‰€ä»¥éœ€è¦å…ˆè¯¢é—®ç—‡çŠ¶ç±»å‹ï¼Œæ¯”å¦‚æ˜¯ç´§å¼ å‹è¿˜æ˜¯åå¤´ç—›ï¼Œè¿™æ ·è¯ç‰©é€‰æ‹©æ‰èƒ½æ›´å‡†ç¡®ã€‚ä¸è¿‡ç”¨æˆ·å¯èƒ½å¸Œæœ›å¾—åˆ°ä¸€èˆ¬æ€§çš„æŒ‡å¯¼ï¼Œæ‰€ä»¥éœ€è¦å¹³è¡¡ä¸“ä¸šæ€§å’Œæ˜“æ‡‚æ€§ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦åˆ—å‡ºå¸¸è§çš„å¤´ç—›åŸå› ï¼Œç¡®ä¿è¦†ç›–ä¸»è¦ç±»å‹ã€‚æ¯”å¦‚ç´§å¼ æ€§å¤´ç—›é€šå¸¸ä¸å‹åŠ›æœ‰å…³ï¼Œå¯èƒ½éœ€è¦éç”¾ä½“æŠ—ç‚è¯ï¼›åå¤´ç—›å¯èƒ½éœ€è¦æŠ—å‡è¡€è¯æˆ–è€…é’™é€šé“é˜»æ»å‰‚ï¼›ä¸›é›†æ€§å¤´ç—›å¯èƒ½éœ€è¦ç‰¹å®šçš„è¯ç‰©å¦‚æ°Ÿæ¡‚åˆ©å—ªæˆ–æ›²æ™®å¦ç±»ã€‚è¿˜æœ‰è¡€ç®¡æ€§å¤´ç—›å¯èƒ½éœ€è¦è¡€ç®¡æ”¶ç¼©å‰‚æˆ–è€…é’™é€šé“è°ƒèŠ‚å‰‚ã€‚é¢…å†…å‹å¢é«˜å¯èƒ½éœ€è¦é™é¢…å‹è¯ç‰©ï¼Œä½†è¿™ç§æƒ…å†µéœ€è¦ä¸“ä¸šè¯Šæ–­ã€‚\n",
      "\n",
      "ç„¶åï¼Œæ ¹æ®ä¸åŒçš„åŸå› ï¼Œè¯ç‰©çš„åˆ†ç±»ä¹Ÿè¦å¯¹åº”ã€‚æ¯”å¦‚ï¼Œé’™é€šé“é˜»æ»å‰‚ï¼ˆå¦‚æ°Ÿæ¡‚åˆ©å—ªï¼‰å¸¸ç”¨äºåå¤´ç—›å’Œè¡€ç®¡æ€§å¤´ç—›ã€‚æŠ—å‡è¡€è¯å¦‚åæ³•æ—ç”¨äºåå¤´ç—›ï¼Œå› ä¸ºåå¤´ç—›å¯èƒ½æœ‰è¡€æ “å½¢æˆçš„é£é™©ã€‚æ›²æ™®å¦ç±»å¦‚èˆ’é©¬æ›²æ™®å¦ç”¨äºæ€¥æ€§åå¤´ç—›å‘ä½œã€‚è¡€ç®¡æ‰©å¼ å‰‚å¦‚æ°Ÿæ¡‚åˆ©å—ªå¯èƒ½ç”¨äºè¡€ç®¡æ€§å¤´ç—›ã€‚é™é¢…å‹è¯ç‰©å¦‚ç”˜éœ²é†‡ç”¨äºé¢…å†…å‹å¢é«˜çš„æƒ…å†µã€‚\n",
      "\n",
      "ç”¨æˆ·å¯èƒ½éœ€è¦çŸ¥é“åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä½¿ç”¨å“ªç§è¯ç‰©ï¼Œæ¯”å¦‚æ€¥æ€§å‘ä½œæ—¶ç”¨æ›²æ™®å¦ï¼Œé•¿æœŸé¢„é˜²å¯èƒ½ç”¨æ°Ÿæ¡‚åˆ©å—ªã€‚å¦å¤–ï¼Œå¦‚æœç—‡çŠ¶ä¸¥é‡æˆ–æŒç»­ï¼Œåº”è¯¥å°½å¿«å°±åŒ»ï¼Œé¿å…è‡ªè¡Œç”¨è¯å»¶è¯¯æ²»ç–—ã€‚\n",
      "\n",
      "è¿˜è¦æ³¨æ„ç”¨æˆ·å¯èƒ½æ²¡æœ‰æ˜ç¡®è¯´æ˜ç—‡çŠ¶çš„å…·ä½“ç±»å‹ï¼Œæ‰€ä»¥å›ç­”ä¸­éœ€è¦å»ºè®®ä»–ä»¬è¯¦ç»†æè¿°ç—‡çŠ¶ï¼Œä»¥ä¾¿åŒ»ç”Ÿåˆ¤æ–­ã€‚åŒæ—¶ï¼Œå¼ºè°ƒè¯ç‰©çš„é€‰æ‹©éœ€è¦ä¸“ä¸šåŒ»ç”Ÿçš„æŒ‡å¯¼ï¼Œé¿å…è‡ªè¡Œç”¨è¯çš„é£é™©ã€‚\n",
      "\n",
      "æ€»ç»“ä¸‹æ¥ï¼Œå›ç­”çš„ç»“æ„åº”è¯¥æ˜¯å…ˆåˆ†ç±»å¤´ç—›åŸå› ï¼Œç„¶ååˆ†ç‚¹è¯´æ˜æ¯ç§åŸå› å¯¹åº”çš„è¯ç‰©ï¼Œæœ€åå»ºè®®å°±åŒ»å’Œæè¿°ç—‡çŠ¶ã€‚è¿™æ ·æ—¢ä¸“ä¸šåˆæ˜“æ‡‚ï¼Œç¬¦åˆç”¨æˆ·çš„éœ€æ±‚ã€‚\n",
      "<|FunctionCallEnd|> \n",
      " æ‚¨å¥½ï¼Œå¤´ç—›çš„åŸå› æœ‰å¾ˆå¤šï¼Œæ¯”å¦‚ç´§å¼ æ€§å¤´ç—›ã€åå¤´ç—›ã€ä¸›é›†æ€§å¤´ç—›ã€è¡€ç®¡æ€§å¤´ç—›ã€é¢…å†…å‹å¢é«˜ç­‰ã€‚é’ˆå¯¹ä¸åŒçš„åŸå› ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›¸åº”çš„è¯ç‰©ã€‚ä¾‹å¦‚ï¼Œåå¤´ç—›å‘ä½œæ—¶ï¼Œå¯ä»¥ä½¿ç”¨é’™é€šé“é˜»æ»å‰‚æˆ–æŠ—å‡è¡€è¯ï¼›è¡€ç®¡æ€§å¤´ç—›å¯ä»¥ä½¿ç”¨è¡€ç®¡æ‰©å¼ å‰‚æˆ–é’™é€šé“è°ƒèŠ‚å‰‚ï¼›è€Œé¢…å†…å‹å¢é«˜åˆ™éœ€è¦ä½¿ç”¨é™é¢…å‹è¯ç‰©ã€‚ä¸è¿‡ï¼Œä¸ºäº†ç¡®ä¿å®‰å…¨å’Œæœ‰æ•ˆï¼Œå»ºè®®æ‚¨è¯¦ç»†æè¿°æ‚¨çš„ç—‡çŠ¶ï¼Œä»¥ä¾¿æˆ‘ä»¬ä¸ºæ‚¨é€‰æ‹©æœ€é€‚åˆçš„è¯ç‰©ã€‚å¦‚æœå¤´ç—›ä¸¥é‡æˆ–æŒç»­ä¸ç¼“è§£ï¼Œä¹Ÿè¯·å°½å¿«å°±åŒ»ï¼Œä»¥ä¾¿å¾—åˆ°ä¸“ä¸šçš„è¯Šæ–­å’Œæ²»ç–—ã€‚<|endoftext|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "def predict_stream_simple(messages, model, tokenizer):\n",
    "    \"\"\"\n",
    "    æµå¼é¢„æµ‹å‡½æ•°ï¼šä½¿ç”¨TextStreamerç›´æ¥åœ¨æ§åˆ¶å°æ‰“å°è¾“å‡º\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # åº”ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–è¾“å…¥\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # åˆ›å»º TextStreamer\n",
    "    # skip_prompt=True ä¼šè·³è¿‡æ‰“å°è¾“å…¥çš„éƒ¨åˆ†ï¼Œåªæ‰“å°æ¨¡å‹ç”Ÿæˆçš„å†…å®¹\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "    \n",
    "    # æµå¼ç”Ÿæˆå›åº”ï¼Œè¿™é‡Œä¼šç›´æ¥æ‰“å°åˆ°å±å¹•\n",
    "    # æ³¨æ„ï¼šgenerateå‡½æ•°ç°åœ¨ä¼šé˜»å¡ç›´åˆ°ç”Ÿæˆç»“æŸï¼Œä½†è¿‡ç¨‹ä¸­ä¼šæµå¼æ‰“å°\n",
    "    _ = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        streamer=streamer # å…³é”®å‚æ•°ï¼šä¼ å…¥streamer\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ç¡®ä¿ä½ çš„è·¯å¾„æ˜¯æ­£ç¡®çš„\n",
    "    final_lora_path = 'Qwen3-1.7B-LoRA/final_lora_adapter'\n",
    "    model_dir = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(final_lora_path):\n",
    "        raise FileNotFoundError(f\"LoRA adapter path not found: {final_lora_path}\")\n",
    "    if not os.path.exists(model_dir):\n",
    "         raise FileNotFoundError(f\"Base model path not found: {model_dir}\")\n",
    "\n",
    "    # é‡æ–°åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    # åŠ è½½LoRAé€‚é…å™¨å¹¶ä¸åŸºç¡€æ¨¡å‹åˆå¹¶\n",
    "    model = PeftModel.from_pretrained(base_model, final_lora_path)\n",
    "    model = model.merge_and_unload() # åˆå¹¶æƒé‡\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir,\n",
    "        use_fast=False,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    instruction = \"ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¸“å®¶ï¼Œä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºå¸¦æœ‰æ€è€ƒçš„å›ç­”ã€‚\"\n",
    "    question = \"ä½ å¥½ï¼ŒåŒ»ç”Ÿï¼Œæˆ‘ç°åœ¨å¤´ç—›çš„å‰å®³ï¼Œåƒä»€ä¹ˆè¯å¯ä»¥ç¼“è§£å‘¢\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    print(\"å›ç­”ï¼š\", end=\"\", flush=True)\n",
    "    # ç›´æ¥è°ƒç”¨æ–°çš„å‡½æ•°\n",
    "    predict_stream_simple(messages, model, tokenizer)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ab485-ad7e-4d58-936c-5359527b0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "def predict_and_stream(messages, model, tokenizer):\n",
    "    \"\"\"\n",
    "    ä¿®æ”¹åçš„æµå¼é¢„æµ‹å‡½æ•°ï¼š\n",
    "    1. ä½¿ç”¨TextStreamerç›´æ¥åœ¨æ§åˆ¶å°æ‰“å°è¾“å‡ºã€‚\n",
    "    2. è¿”å›æ¨¡å‹ç”Ÿæˆçš„å®Œæ•´å›å¤æ–‡æœ¬ï¼Œç”¨äºæ·»åŠ åˆ°å¯¹è¯å†å²ä¸­ã€‚\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # åº”ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–è¾“å…¥\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    input_ids = model_inputs.input_ids\n",
    "    input_length = input_ids.shape[1] # è®°å½•è¾“å…¥å†…å®¹çš„é•¿åº¦\n",
    "\n",
    "    # åˆ›å»º TextStreamer\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "    \n",
    "    # ä½¿ç”¨ streamer è¿›è¡Œæµå¼è¾“å‡ºï¼ŒåŒæ—¶æ¥æ”¶å®Œæ•´çš„ç”Ÿæˆç»“æœ\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        streamer=streamer\n",
    "    )\n",
    "    \n",
    "    # ä»è¿”å›çš„ generated_ids ä¸­è§£ç å‡ºå®Œæ•´çš„å›å¤\n",
    "    # éœ€è¦å»æ‰è¾“å…¥éƒ¨åˆ†ï¼Œåªä¿ç•™æ–°ç”Ÿæˆçš„éƒ¨åˆ†\n",
    "    response_ids = generated_ids[0][input_length:]\n",
    "    response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- æ¨¡å‹åŠ è½½éƒ¨åˆ† (ä¸ä¹‹å‰ç›¸åŒ) ---\n",
    "    final_lora_path = 'Qwen3-1.7B-LoRA/final_lora_adapter'\n",
    "    model_dir = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "    if not os.path.exists(final_lora_path):\n",
    "        raise FileNotFoundError(f\"LoRA adapter path not found: {final_lora_path}\")\n",
    "    if not os.path.exists(model_dir):\n",
    "         raise FileNotFoundError(f\"Base model path not found: {model_dir}\")\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, final_lora_path)\n",
    "    model = model.merge_and_unload()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir,\n",
    "        use_fast=False,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # --- èŠå¤©å¾ªç¯éƒ¨åˆ† (æ ¸å¿ƒä¿®æ”¹) ---\n",
    "    \n",
    "    # 1. åˆå§‹åŒ–å¯¹è¯å†å²ï¼ŒåŒ…å«ç³»ç»ŸæŒ‡ä»¤\n",
    "    instruction = \"ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¸“å®¶ï¼Œä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºå¸¦æœ‰æ€è€ƒçš„å›ç­”ã€‚\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction}\n",
    "    ]\n",
    "    \n",
    "    print(\"åŒ»å­¦ä¸“å®¶å·²ä¸Šçº¿ã€‚è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºç¨‹åºã€‚\")\n",
    "    \n",
    "    # 2. å¯åŠ¨ä¸€ä¸ªæ— é™å¾ªç¯æ¥è¿›è¡Œå¯¹è¯\n",
    "    while True:\n",
    "        # è·å–ç”¨æˆ·è¾“å…¥\n",
    "        question = input(\"ä½ : \")\n",
    "        \n",
    "        if question.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼\")\n",
    "            break\n",
    "            \n",
    "        # 3. å°†ç”¨æˆ·çš„æé—®æ·»åŠ åˆ°å†å²è®°å½•\n",
    "        messages.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        print(\"ä¸“å®¶: \", end=\"\", flush=True)\n",
    "        \n",
    "        # 4. è°ƒç”¨æ¨¡å‹ï¼Œä¼ å…¥å®Œæ•´çš„å¯¹è¯å†å²\n",
    "        # å‡½æ•°ä¼šæµå¼æ‰“å°ç­”æ¡ˆï¼Œå¹¶è¿”å›å®Œæ•´çš„ç­”æ¡ˆæ–‡æœ¬\n",
    "        assistant_response = predict_and_stream(messages, model, tokenizer)\n",
    "        \n",
    "        # æ¢è¡Œï¼Œä»¥ä¾¿ä¸‹ä¸€æ¬¡è¾“å…¥\n",
    "        print() \n",
    "        \n",
    "        # 5. å°†æ¨¡å‹çš„å›ç­”ä¹Ÿæ·»åŠ åˆ°å†å²è®°å½•ï¼Œä¸ºä¸‹ä¸€æ¬¡å¯¹è¯åšå‡†å¤‡\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
